{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_fusion.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOSe9nnEQyqnnBP++FYX2f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd3FFqcgfzPb"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sporco.util import tikhonov_filter\n",
        "\n",
        "import torch\n",
        "from torchvision.models.vgg import vgg19\n",
        "\n",
        "def lowpass(s, lda, npad):\n",
        "    return tikhonov_filter(s, lda, npad)\n",
        "\n",
        "def c3(s):\n",
        "    if s.ndim == 2:\n",
        "        s3 = np.dstack([s, s, s])\n",
        "    else:\n",
        "        s3 = s\n",
        "    return np.rollaxis(s3, 2, 0)[None, :, :, :]\n",
        "\n",
        "def l1_features(out):\n",
        "    h, w, d = out.shape\n",
        "    A_temp = np.zeros((h+2, w+2))\n",
        "    \n",
        "    l1_norm = np.sum(np.abs(out), axis=2)\n",
        "    A_temp[1:h+1, 1:w+1] = l1_norm\n",
        "    return A_temp\n",
        "\n",
        "def fusion_strategy(feat_a, feat_b, source_a, source_b, unit):\n",
        "    \n",
        "    m, n = feat_a.shape\n",
        "    m1, n1 = source_a.shape[:2]\n",
        "    weight_ave_temp1 = np.zeros((m1, n1))\n",
        "    weight_ave_temp2 = np.zeros((m1, n1))\n",
        "    \n",
        "    for i in range(1, m):\n",
        "        for j in range(1, n):\n",
        "            A1 = feat_a[i-1:i+1, j-1:j+1].sum() / 9\n",
        "            A2 = feat_b[i-1:i+1, j-1:j+1].sum() / 9\n",
        "            \n",
        "            weight_ave_temp1[(i-2)*unit+1:(i-1)*unit+1, (j-2)*unit+1:(j-1)*unit+1] = A1 / (A1+A2)\n",
        "            weight_ave_temp2[(i-2)*unit+1:(i-1)*unit+1, (j-2)*unit+1:(j-1)*unit+1] = A2 / (A1+A2)\n",
        "\n",
        "    if source_a.ndim == 3:\n",
        "        weight_ave_temp1 = weight_ave_temp1[:, :, None]\n",
        "    source_a_fuse = source_a * weight_ave_temp1\n",
        "    if source_b.ndim == 3:\n",
        "        weight_ave_temp2 = weight_ave_temp2[:, :, None]\n",
        "    source_b_fuse = source_b * weight_ave_temp2\n",
        "    \n",
        "    if source_a.ndim == 3 or source_b.ndim == 3:\n",
        "        gen = np.atleast_3d(source_a_fuse) + np.atleast_3d(source_b_fuse)\n",
        "    else:\n",
        "        gen = source_a_fuse + source_b_fuse\n",
        "    \n",
        "    return gen\n",
        "\n",
        "def get_activation(model, layer_numbers, input_image):\n",
        "    outs = []\n",
        "    out = input_image\n",
        "    for i in range(max(layer_numbers)+1):\n",
        "        with torch.no_grad():\n",
        "            out = model.features[i](out)\n",
        "        if i in layer_numbers:\n",
        "            outs.append(np.rollaxis(out.detach().cpu().numpy()[0], 0, 3))\n",
        "    return outs\n",
        "\n",
        "def fuse(vis, ir, model=None):\n",
        "    npad = 16\n",
        "    lda = 5\n",
        "    vis_low, vis_high = lowpass(vis.astype(np.float32)/255, lda, npad)\n",
        "    ir_low, ir_high = lowpass(ir.astype(np.float32)/255, lda, npad)\n",
        "    \n",
        "    if model is None:\n",
        "        model = vgg19(True)\n",
        "    model.cuda().eval()\n",
        "    relus = [2, 7, 12, 21]\n",
        "    unit_relus = [1, 2, 4, 8]\n",
        "    \n",
        "    vis_in = torch.from_numpy(c3(vis_high)).cuda()\n",
        "    ir_in = torch.from_numpy(c3(ir_high)).cuda()\n",
        "    \n",
        "    relus_vis = get_activation(model, relus, vis_in)\n",
        "    relus_ir = get_activation(model, relus, ir_in)\n",
        "    \n",
        "    vis_feats = [l1_features(out) for out in relus_vis]\n",
        "    ir_feats = [l1_features(out) for out in relus_ir]\n",
        "    \n",
        "    saliencies = []\n",
        "    saliency_max = None\n",
        "    for idx in range(len(relus)):\n",
        "        saliency_current = fusion_strategy(vis_feats[idx], ir_feats[idx], vis_high, ir_high, unit_relus[idx])\n",
        "        saliencies.append(saliency_current)\n",
        "\n",
        "        if saliency_max is None:\n",
        "            saliency_max = saliency_current\n",
        "        else:\n",
        "            saliency_max = np.maximum(saliency_max, saliency_current)\n",
        "            \n",
        "    if vis_low.ndim == 3 or ir_low.ndim == 3:\n",
        "        low_fused = np.atleast_3d(vis_low) + np.atleast_3d(ir_low)\n",
        "    else:\n",
        "        low_fused = vis_low + ir_low\n",
        "    low_fused = low_fused / 2\n",
        "    high_fused = saliency_max\n",
        "    return low_fused + high_fused"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFHk2I2Gf0NO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}